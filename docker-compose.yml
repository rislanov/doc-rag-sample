version: '3.8'

services:
  # PostgreSQL Database with pgvector
  postgres:
    image: pgvector/pgvector:pg15
    container_name: docrag-postgres
    environment:
      POSTGRES_DB: docrag
      POSTGRES_USER: docrag
      POSTGRES_PASSWORD: docrag
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U docrag -d docrag"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - docrag-network

  # RabbitMQ Message Broker
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: docrag-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    ports:
      - "5672:5672"
      - "15672:15672"  # Management UI
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - docrag-network

  # Ollama LLM Server
  ollama:
    image: ollama/ollama:latest
    container_name: docrag-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # For GPU support on Linux, uncomment:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - docrag-network

  # Ollama Model Puller (one-time job)
  ollama-pull:
    image: curlimages/curl:latest
    container_name: docrag-ollama-pull
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: >
      sh -c "
        echo 'Waiting for Ollama to be ready...' &&
        sleep 5 &&
        echo 'Pulling Mistral 7B model...' &&
        curl -X POST http://ollama:11434/api/pull -d '{\"name\": \"mistral:7b-instruct\"}' &&
        echo 'Pulling enbeddrus embedding model...' &&
        curl -X POST http://ollama:11434/api/pull -d '{\"name\": \"evilfreelancer/enbeddrus\"}' &&
        echo 'All models pulled successfully!'
      "
    networks:
      - docrag-network

  # Recognizer Service (OCR)
  recognizer:
    build:
      context: ./recognizer
      dockerfile: Dockerfile
    container_name: docrag-recognizer
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: docrag
      POSTGRES_USER: docrag
      POSTGRES_PASSWORD: docrag
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: guest
      RABBITMQ_PASSWORD: guest
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - docrag-network

  # Semantic Chunker Service
  semantic-chunker:
    build:
      context: ./semantic-chunker
      dockerfile: Dockerfile
    container_name: docrag-semantic-chunker
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: docrag
      POSTGRES_USER: docrag
      POSTGRES_PASSWORD: docrag
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: guest
      RABBITMQ_PASSWORD: guest
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: mistral:7b-instruct
      EMBEDDING_MODEL: evilfreelancer/enbeddrus
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      ollama-pull:
        condition: service_completed_successfully
    restart: unless-stopped
    networks:
      - docrag-network

  # DocRAG API Service (.NET)
  doc-rag-api:
    build:
      context: ./doc-rag
      dockerfile: Dockerfile
    container_name: docrag-api
    environment:
      ASPNETCORE_ENVIRONMENT: Production
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=docrag;Username=docrag;Password=docrag"
      Ollama__BaseUrl: http://ollama:11434
      Ollama__Model: mistral:7b-instruct
      Ollama__EmbeddingModel: evilfreelancer/enbeddrus
      Ollama__UseHybridSearch: "true"
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      ollama-pull:
        condition: service_completed_successfully
    restart: unless-stopped
    networks:
      - docrag-network

volumes:
  postgres_data:
  rabbitmq_data:
  ollama_data:

networks:
  docrag-network:
    driver: bridge
